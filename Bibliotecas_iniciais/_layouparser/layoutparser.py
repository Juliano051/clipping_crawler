# -*- coding: utf-8 -*-
"""layoutparser.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tYDkIMvFv_oH9KFcIwj2TmfjLNeGr7Ch
"""

!pip install -U layoutparser
!pip install pymupdf
!pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2'
!pip install layoutparser[ocr]
!git clone https://github.com/Layout-Parser/layout-parser.git

!pip install -U layoutparser

!pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.4#egg=detectron2'

!pip install layoutparser[ocr]

!git clone https://github.com/Layout-Parser/layout-parser.git

# Commented out IPython magic to ensure Python compatibility.
# %cd layout-parser/

!pip install pymupdf

###
# Converte o pdf em imagens, p치gina por p치gina
###
import fitz # depende do pymupdf
doc = fitz.open('./tests/dope996.pdf')
zoom = 2  # to increase the resolution
mat = fitz.Matrix(zoom, zoom)
noOfPages = doc.page_count
image_folder = './output/'

for pageNo in range(noOfPages):
    page = doc.load_page(pageNo)  # number of page
    pix = page.get_pixmap(matrix=mat)

    # you could change image format accordingly
    output = image_folder + str(pageNo) + '.jpg'
    pix.save(output)
    print('Converting PDFs to Image ... ' + output)
    # do your things afterwards

import cv2
image = cv2.imread("/content/layout-parser/output/1.jpg")
image2 = cv2.imread("/content/layout-parser/output/2.jpg")
#image = cv2.imread("/page-2.jpg")
image = image[...,::-1]

###
# Realiza a leitura da imagem do documento, delimitando as 치reas de par치grafo, imagens, tabelas, etc.
###
import layoutparser as lp

model = lp.Detectron2LayoutModel('lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config', 
                                 extra_config=["MODEL.ROI_HEADS.SCORE_THRESH_TEST", 0.6],
                                 label_map={0: "Text", 1: "Title", 2: "List", 3:"Table", 4:"Figure"})

# model = lp.Detectron2LayoutModel(
#             config_path ='lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config', # In model catalog
#             label_map   ={0: "Text", 1: "Title", 2: "List", 3:"Table", 4:"Figure"}, # In model`label_map`
#             extra_config=["MODEL.ROI_HEADS.SCORE_THRESH_TEST", 0.8] # Optional
#         )

# model = lp.Detectron2LayoutModel('lp://PrimaLayout/mask_rcnn_R_50_FPN_3x/config',
#                                  extra_config=["MODEL.ROI_HEADS.SCORE_THRESH_TEST", 0.9],
#                                  label_map={1:"TextRegion", 2:"ImageRegion", 3:"TableRegion", 4:"MathsRegion", 5:"SeparatorRegion", 6:"OtherRegion"},
#                                  )

# model = lp.Detectron2LayoutModel('lp://NewspaperNavigator/faster_rcnn_R_50_FPN_3x/config',
#                                  extra_config=["MODEL.ROI_HEADS.SCORE_THRESH_TEST", 0.8],
#                                  label_map={0: "Photograph", 1: "Illustration", 2: "Map", 3: "Comics/Cartoon", 4: "Editorial Cartoon", 5: "Headline", 6: "Advertisement"})

layout = model.detect(image)
lp.draw_box(image, layout, box_width=2, color_map = {'Text':'red', 'Title':'blue','List':'green','Table':'purple','Figure':'pink', 'Image':'pink'}, show_element_type=True)

#type(layout)
image_width = len(image[0])

# Sort element ID of the left column based on y1 coordinate
left_interval = lp.Interval(0, image_width/2, axis='x').put_on_canvas(image)
left_blocks = layout.filter_by(left_interval, center=True)._blocks
left_blocks.sort(key = lambda b:b.coordinates[1])

# Sort element ID of the right column based on y1 coordinate
right_blocks = [b for b in layout if b not in left_blocks]
right_blocks.sort(key = lambda b:b.coordinates[1])

# Sort the overall element ID starts from left column
layout = lp.Layout([b.set(id = idx) for idx, b in enumerate(left_blocks + right_blocks)])

!sudo apt install tesseract-ocr

!pip install pytesseract

import pytesseract

import shutil

import os

import random

try:
  from PIL import Image

except ImportError:
  import Image

# !apt-get install tesseract-ocr-por  #for english
!ls

ocr_agent = lp.TesseractAgent(languages='por')

import pytesseract

for block in layout:

    # Crop image around the detected layout
    segment_image = (block
                       .pad(left=15, right=15, top=5, bottom=5)
                       .crop_image(image))
    text = ocr_agent.detect(segment_image)
    # Perform OCR
    # text = ocr_agent.detect(segment_image)

    # Save OCR result
    block.set(text=text, inplace=True)

for txt in layout:
    print(txt.text, end='\n*************\n')